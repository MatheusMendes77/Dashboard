# dashboard_app.py
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import numpy as np
from datetime import datetime
import os
import scipy.stats as stats
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√£o da p√°gina
st.set_page_config(page_title="Dashboard de An√°lise de Processos", layout="wide")

# Fun√ß√£o para gerar IDs √∫nicos
def generate_unique_key(*args):
    return "_".join(str(arg) for arg in args)

# Fun√ß√£o para carregar dados
@st.cache_data
def carregar_dados(uploaded_file):
    """Carrega os dados do arquivo Excel com cache para melhor performance"""
    try:
        if uploaded_file.name.endswith('.csv'):
            dados = pd.read_csv(uploaded_file)
        else:
            dados = pd.read_excel(uploaded_file)
        return dados
    except Exception as e:
        st.error(f"Erro ao carregar arquivo: {str(e)}")
        return None

# Fun√ß√£o para converter para data
def converter_para_data(coluna):
    """Tenta converter uma coluna para datetime"""
    try:
        return pd.to_datetime(coluna, dayfirst=True, errors='coerce')
    except:
        return coluna

# Fun√ß√£o para detectar outliers
def detectar_outliers(dados, coluna):
    if coluna not in dados.columns:
        return pd.DataFrame(), pd.Series()
    
    Q1 = dados[coluna].quantile(0.25)
    Q3 = dados[coluna].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers_mask = (dados[coluna] < lower_bound) | (dados[coluna] > upper_bound)
    return dados[outliers_mask], outliers_mask

# Fun√ß√£o para detectar outliers usando Z-score
def detectar_outliers_zscore(dados, coluna, threshold=3):
    if coluna not in dados.columns:
        return pd.DataFrame(), pd.Series()
    
    z_scores = np.abs(stats.zscore(dados[coluna].dropna()))
    outliers_mask = z_scores > threshold
    return dados[outliers_mask], outliers_mask

# Fun√ß√£o para calcular regress√£o linear manualmente
def calcular_regressao_linear(x, y):
    """Calcula regress√£o linear manualmente"""
    # Remover valores NaN
    mask = ~np.isnan(x) & ~np.isnan(y)
    x_clean = x[mask]
    y_clean = y[mask]
    
    if len(x_clean) < 2:
        return None, None, None
    
    n = len(x_clean)
    x_mean = np.mean(x_clean)
    y_mean = np.mean(y_clean)
    
    numerator = np.sum((x_clean - x_mean) * (y_clean - y_mean))
    denominator = np.sum((x_clean - x_mean) ** 2)
    
    if denominator == 0:
        return None, None, None
    
    slope = numerator / denominator
    intercept = y_mean - slope * x_mean
    
    # Calcular R¬≤
    y_pred = slope * x_clean + intercept
    ss_res = np.sum((y_clean - y_pred) ** 2)
    ss_tot = np.sum((y_clean - y_mean) ** 2)
    r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
    
    return slope, intercept, r_squared

# Fun√ß√£o para criar gr√°fico Q-Q correto
def criar_qq_plot_correto(data):
    """Cria gr√°fico Q-Q correto passando pelo meio dos pontos"""
    data_clean = data.dropna()
    if len(data_clean) < 2:
        return go.Figure()
    
    # Calcular quantis te√≥ricos normais
    theoretical_quantiles = stats.probplot(data_clean, dist="norm")[0][0]
    sample_quantiles = stats.probplot(data_clean, dist="norm")[0][1]
    
    # Calcular linha de tend√™ncia para o Q-Q plot
    z = np.polyfit(theoretical_quantiles, sample_quantiles, 1)
    p = np.poly1d(z)
    
    fig = go.Figure()
    
    # Adicionar pontos
    fig.add_trace(go.Scatter(
        x=theoretical_quantiles,
        y=sample_quantiles,
        mode='markers',
        name='Dados',
        marker=dict(color='blue', size=6)
    ))
    
    # Adicionar linha de tend√™ncia que passa pelo meio dos pontos
    fig.add_trace(go.Scatter(
        x=theoretical_quantiles,
        y=p(theoretical_quantiles),
        mode='lines',
        name='Linha de Tend√™ncia',
        line=dict(color='red', width=2)
    ))
    
    fig.update_layout(
        title="Gr√°fico Q-Q (An√°lise de Normalidade)",
        xaxis_title="Quantis Te√≥ricos",
        yaxis_title="Quantis Amostrais",
        showlegend=True
    )
    
    return fig

# Fun√ß√£o para an√°lise de capacidade do processo
def analise_capacidade_processo(dados, coluna, lse, lie):
    """Analisa a capacidade do processo"""
    if coluna not in dados.columns:
        return None
    
    data_clean = dados[coluna].dropna()
    if len(data_clean) < 2:
        return None
    
    media = np.mean(data_clean)
    desvio_padrao = np.std(data_clean, ddof=1)
    
    resultados = {
        'media': media,
        'desvio_padrao': desvio_padrao,
        'n': len(data_clean)
    }
    
    if lse is not None and lie is not None:
        # Cp - Capacidade do processo
        cp = (lse - lie) / (6 * desvio_padrao)
        # Cpk - Capacidade real do processo
        cpk = min((lse - media) / (3 * desvio_padrao), (media - lie) / (3 * desvio_padrao))
        
        resultados.update({
            'cp': cp,
            'cpk': cpk,
            'lse': lse,
            'lie': lie
        })
    
    return resultados

# Fun√ß√£o para criar gr√°fico de controle
def criar_grafico_controle(dados, coluna_valor, coluna_data=None):
    """Cria gr√°fico de controle (X-bar)"""
    if coluna_valor not in dados.columns:
        return go.Figure()
    
    data_clean = dados[[coluna_valor]].copy()
    if coluna_data and coluna_data in dados.columns:
        data_clean[coluna_data] = dados[coluna_data]
        data_clean = data_clean.sort_values(coluna_data)
    
    # Calcular limites de controle
    media = data_clean[coluna_valor].mean()
    std = data_clean[coluna_valor].std()
    
    lsc = media + 3 * std  # Limite Superior de Controle
    lic = media - 3 * std  # Limite Inferior de Controle
    lc = media             # Linha Central
    
    fig = go.Figure()
    
    # Adicionar pontos do processo
    if coluna_data:
        x_data = data_clean[coluna_data]
    else:
        x_data = list(range(len(data_clean)))
    
    fig.add_trace(go.Scatter(
        x=x_data,
        y=data_clean[coluna_valor],
        mode='lines+markers',
        name='Valores',
        line=dict(color='blue', width=2),
        marker=dict(size=6)
    ))
    
    # Adicionar linhas de controle
    fig.add_hline(y=lsc, line_dash="dash", line_color="red", annotation_text="LSC")
    fig.add_hline(y=lc, line_dash="dash", line_color="green", annotation_text="LC")
    fig.add_hline(y=lic, line_dash="dash", line_color="red", annotation_text="LIC")
    
    fig.update_layout(
        title=f"Gr√°fico de Controle - {coluna_valor}",
        xaxis_title=coluna_data if coluna_data else "Amostras",
        yaxis_title=coluna_valor,
        showlegend=True
    )
    
    return fig, lsc, lc, lic

def main():
    st.title("üè≠ Dashboard de An√°lise de Processos Industriais")
    
    # Inicializar estado da sess√£o
    session_defaults = {
        'dados_originais': None,
        'dados_processados': None,
        'filtro_data_limpo': False,
        'outliers_removidos': {},
        'lse_values': {},
        'lie_values': {}
    }
    
    for key, value in session_defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value
    
    # Sidebar para upload
    with st.sidebar:
        st.header("üìÅ Carregamento de Dados")
        
        uploaded_file = st.file_uploader(
            "Selecione o arquivo de dados:",
            type=['xlsx', 'xls', 'csv'],
            key=generate_unique_key("file_uploader", "main")
        )
        
        if uploaded_file is not None:
            st.success("‚úÖ Arquivo selecionado!")
        else:
            st.info("üìù Aguardando upload do arquivo...")
            st.stop()

    # Carregar dados
    dados = carregar_dados(uploaded_file)
    
    if dados is None:
        st.error("‚ùå Falha ao carregar os dados.")
        st.stop()

    # Inicializar dados na sess√£o se necess√°rio
    if st.session_state.dados_originais is None:
        st.session_state.dados_originais = dados.copy()
        st.session_state.dados_processados = dados.copy()

    # Processar dados
    dados_processados = st.session_state.dados_processados.copy()
    colunas_numericas = dados_processados.select_dtypes(include=[np.number]).columns.tolist()
    
    # Detectar colunas de data
    colunas_data = []
    for col in dados_processados.columns:
        if any(palavra in col.lower() for palavra in ['data', 'date', 'dia', 'time', 'hora', 'timestamp']):
            colunas_data.append(col)
            dados_processados[col] = converter_para_data(dados_processados[col])

    # Sidebar para filtros globais
    with st.sidebar:
        st.header("üéõÔ∏è Filtros Globais")
        
        # Bot√£o para resetar todos os filtros
        if st.button("üîÑ Resetar Todos os Filtros", use_container_width=True,
                    key=generate_unique_key("reset_filters", "main")):
            st.session_state.dados_processados = st.session_state.dados_originais.copy()
            st.session_state.filtro_data_limpo = False
            st.session_state.outliers_removidos = {}
            st.session_state.lse_values = {}
            st.session_state.lie_values = {}
            st.rerun()
        
        # Filtro de per√≠odo
        if colunas_data:
            coluna_data_filtro = st.selectbox("Coluna de data para filtro:", colunas_data,
                                             key=generate_unique_key("data_filter_col", "main"))
            
            if pd.api.types.is_datetime64_any_dtype(dados_processados[coluna_data_filtro]):
                min_date = dados_processados[coluna_data_filtro].min()
                max_date = dados_processados[coluna_data_filtro].max()
                
                # Verificar se o filtro foi limpo
                if st.session_state.filtro_data_limpo:
                    date_range = (min_date, max_date)
                else:
                    date_range = st.date_input(
                        "Selecione o per√≠odo:",
                        value=(min_date, max_date),
                        min_value=min_date,
                        max_value=max_date,
                        key=generate_unique_key("date_range", "main")
                    )
                
                # Bot√£o para limpar filtro de data
                if st.button("‚ùå Limpar Filtro de Data", use_container_width=True,
                            key=generate_unique_key("clear_date_filter", "main")):
                    st.session_state.filtro_data_limpo = True
                    st.rerun()
                
                if len(date_range) == 2 and not st.session_state.filtro_data_limpo:
                    start_date, end_date = date_range
                    dados_processados = dados_processados[
                        (dados_processados[coluna_data_filtro] >= pd.Timestamp(start_date)) &
                        (dados_processados[coluna_data_filtro] <= pd.Timestamp(end_date))
                    ]
        
        # Filtro de outliers - CORRIGIDO
        st.subheader("üîç Gerenciamento de Outliers")
        
        if colunas_numericas:
            coluna_outliers = st.selectbox("Selecione a coluna para an√°lise de outliers:", colunas_numericas,
                                          key=generate_unique_key("outlier_col", "main"))
            
            if coluna_outliers:
                # Selecionar m√©todo de detec√ß√£o de outliers
                metodo_outliers = st.radio("M√©todo de detec√ß√£o:", 
                                          ["IQR (Recomendado)", "Z-Score"],
                                          key=generate_unique_key("outlier_method", coluna_outliers))
                
                # Detectar outliers
                if metodo_outliers == "IQR (Recomendado)":
                    outliers_df, outliers_mask = detectar_outliers(dados_processados, coluna_outliers)
                else:
                    outliers_df, outliers_mask = detectar_outliers_zscore(dados_processados, coluna_outliers)
                
                st.info(f"üìä {len(outliers_df)} outliers detectados na coluna '{coluna_outliers}'")
                
                # Mostrar outliers
                if len(outliers_df) > 0:
                    with st.expander("üìã Visualizar Outliers Detectados"):
                        st.dataframe(outliers_df[[coluna_outliers]].style.format({
                            coluna_outliers: '{:.4f}'
                        }))
                
                # Op√ß√£o para remover outliers
                col_btn1, col_btn2 = st.columns(2)
                with col_btn1:
                    if st.button(f"üóëÔ∏è Remover Outliers", use_container_width=True,
                                key=generate_unique_key("remove_outliers", coluna_outliers)):
                        dados_sem_outliers = dados_processados[~outliers_mask]
                        st.session_state.dados_processados = dados_sem_outliers
                        st.session_state.outliers_removidos[coluna_outliers] = True
                        st.success(f"‚úÖ {len(outliers_df)} outliers removidos da coluna '{coluna_outliers}'")
                        st.rerun()
                
                with col_btn2:
                    if st.button(f"‚Ü©Ô∏è Restaurar Outliers", use_container_width=True,
                                key=generate_unique_key("restore_outliers", coluna_outliers)):
                        if coluna_outliers in st.session_state.outliers_removidos:
                            st.session_state.dados_processados = st.session_state.dados_originais.copy()
                            del st.session_state.outliers_removidos[coluna_outliers]
                            st.success(f"‚úÖ Outliers restaurados para '{coluna_outliers}'")
                            st.rerun()

        # Configura√ß√£o de limites de especifica√ß√£o
        st.subheader("üéØ Limites de Especifica√ß√£o")
        if colunas_numericas:
            coluna_limites = st.selectbox("Selecione a vari√°vel:", colunas_numericas,
                                         key=generate_unique_key("limits_col", "main"))
            
            col_lim1, col_lim2 = st.columns(2)
            with col_lim1:
                lse = st.number_input("LSE (Limite Superior):", 
                                     value=float(st.session_state.lse_values.get(coluna_limites, 0)),
                                     key=generate_unique_key("lse", coluna_limites))
                st.session_state.lse_values[coluna_limites] = lse
            
            with col_lim2:
                lie = st.number_input("LIE (Limite Inferior):", 
                                     value=float(st.session_state.lie_values.get(coluna_limites, 0)),
                                     key=generate_unique_key("lie", coluna_limites))
                st.session_state.lie_values[coluna_limites] = lie

    # Abas principais - AGRORA MAIS COMPLETAS
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà An√°lise Temporal", 
        "üìä Estat√≠stica Detalhada", 
        "üî• Correla√ß√µes", 
        "üîç Dispers√£o & Regress√£o",
        "üéØ Controle Estat√≠stico",
        "üìã Resumo Executivo"
    ])

    with tab1:
        st.header("üìà An√°lise de S√©ries Temporais")
        
        if colunas_data and colunas_numericas:
            col1, col2, col3 = st.columns([2, 2, 1])
            
            with col1:
                coluna_data = st.selectbox("Coluna de Data:", colunas_data, 
                                          key=generate_unique_key("temp_data", "tab1"))
            with col2:
                coluna_valor = st.selectbox("Coluna para An√°lise:", colunas_numericas,
                                           key=generate_unique_key("temp_valor", "tab1"))
            with col3:
                tipo_grafico = st.selectbox("Tipo de Gr√°fico:", 
                                           ["Linha", "√Årea", "Barra", "Scatter", "Boxplot Temporal", "Histograma Temporal"],
                                           key=generate_unique_key("chart_type", "tab1"))
            
            if coluna_data and coluna_valor:
                dados_temp = dados_processados.sort_values(by=coluna_data)
                
                # Op√ß√£o para remover outliers diretamente no gr√°fico
                remover_outliers_grafico = st.checkbox("üìâ Remover outliers para visualiza√ß√£o",
                                                      key=generate_unique_key("remove_temp_outliers", coluna_valor))
                
                if remover_outliers_grafico:
                    outliers_df, outliers_mask = detectar_outliers(dados_temp, coluna_valor)
                    dados_temp = dados_temp[~outliers_mask]
                    st.info(f"üìä {len(outliers_df)} outliers removidos para visualiza√ß√£o")
                
                # Criar gr√°fico baseado no tipo selecionado
                if tipo_grafico == "Linha":
                    fig = px.line(dados_temp, x=coluna_data, y=coluna_valor, 
                                 title=f"Evolu√ß√£o Temporal de {coluna_valor}")
                elif tipo_grafico == "√Årea":
                    fig = px.area(dados_temp, x=coluna_data, y=coluna_valor,
                                 title=f"Evolu√ß√£o Temporal de {coluna_valor}")
                elif tipo_grafico == "Barra":
                    fig = px.bar(dados_temp, x=coluna_data, y=coluna_valor,
                                title=f"Evolu√ß√£o Temporal de {coluna_valor}")
                elif tipo_grafico == "Scatter":
                    fig = px.scatter(dados_temp, x=coluna_data, y=coluna_valor,
                                    title=f"Rela√ß√£o Temporal de {coluna_valor}")
                elif tipo_grafico == "Histograma Temporal":
                    # Criar histograma 2D
                    fig = px.density_heatmap(dados_temp, x=coluna_data, y=coluna_valor,
                                           title=f"Distribui√ß√£o Temporal de {coluna_valor}")
                else:  # Boxplot Temporal
                    # Criar per√≠odos mensais para boxplot
                    dados_temp['Periodo'] = dados_temp[coluna_data].dt.to_period('M').astype(str)
                    fig = px.box(dados_temp, x='Periodo', y=coluna_valor,
                                title=f"Distribui√ß√£o Mensal de {coluna_valor}")
                
                st.plotly_chart(fig, use_container_width=True)
                
                # An√°lise de tend√™ncia com mais detalhes
                st.subheader("üìà An√°lise de Tend√™ncia Detalhada")
                if len(dados_temp) > 1:
                    # Calcular m√©tricas de tend√™ncia
                    crescimento = ((dados_temp[coluna_valor].iloc[-1] - dados_temp[coluna_valor].iloc[0]) / 
                                 dados_temp[coluna_valor].iloc[0] * 100) if dados_temp[coluna_valor].iloc[0] != 0 else 0
                    
                    # Regress√£o linear para tend√™ncia
                    x = np.arange(len(dados_temp))
                    y = dados_temp[coluna_valor].values
                    coef = np.polyfit(x, y, 1)[0]
                    
                    col_t1, col_t2, col_t3, col_t4 = st.columns(4)
                    with col_t1:
                        st.metric("Crescimento Total", f"{crescimento:.1f}%")
                    with col_t2:
                        tendencia = "‚ÜóÔ∏è Alta" if coef > 0 else "‚ÜòÔ∏è Baixa" if coef < 0 else "‚û°Ô∏è Est√°vel"
                        st.metric("Tend√™ncia", tendencia)
                    with col_t3:
                        st.metric("Taxa de Varia√ß√£o", f"{coef:.4f}")
                    with col_t4:
                        # Calcular volatilidade (desvio padr√£o das varia√ß√µes)
                        variacoes = dados_temp[coluna_valor].pct_change().dropna()
                        volatilidade = variacoes.std() * 100
                        st.metric("Volatilidade", f"{volatilidade:.2f}%")

    with tab2:
        st.header("üìä Estat√≠stica Detalhada")
        
        if colunas_numericas:
            coluna_analise = st.selectbox("Selecione a coluna para an√°lise:", colunas_numericas, 
                                         key=generate_unique_key("stats_col", "tab2"))
            
            if coluna_analise:
                # Op√ß√µes de an√°lise
                col_opt1, col_opt2 = st.columns(2)
                with col_opt1:
                    remover_outliers_grafico = st.checkbox("üìâ Remover outliers para an√°lise",
                                                          key=generate_unique_key("remove_stats_outliers", coluna_analise))
                with col_opt2:
                    usar_log = st.checkbox("üìä Aplicar transforma√ß√£o logar√≠tmica",
                                          key=generate_unique_key("use_log", coluna_analise))
                
                dados_analise = dados_processados.copy()
                if remover_outliers_grafico:
                    outliers_df, outliers_mask = detectar_outliers(dados_analise, coluna_analise)
                    dados_analise = dados_analise[~outliers_mask]
                    st.info(f"üìä {len(outliers_df)} outliers removidos para an√°lise")
                
                if usar_log:
                    dados_analise[coluna_analise] = np.log1p(dados_analise[coluna_analise])
                    st.info("Transforma√ß√£o logar√≠tmica aplicada")
                
                # Estat√≠sticas b√°sicas
                st.subheader("üìã Estat√≠sticas Descritivas Completas")
                stats_data = dados_analise[coluna_analise].describe()
                
                col1, col2, col3, col4 = st.columns(4)
                metrics = [
                    ("M√©dia", stats_data['mean']),
                    ("Mediana", stats_data['50%']),
                    ("Moda", dados_analise[coluna_analise].mode().iloc[0] if not dados_analise[coluna_analise].mode().empty else np.nan),
                    ("Desvio Padr√£o", stats_data['std']),
                    ("Vari√¢ncia", stats_data['std']**2),
                    ("Coef. Varia√ß√£o", (stats_data['std']/stats_data['mean'])*100 if stats_data['mean'] != 0 else 0),
                    ("M√≠nimo", stats_data['min']),
                    ("M√°ximo", stats_data['max']),
                    ("Amplitude", stats_data['max'] - stats_data['min']),
                    ("Q1 (25%)", stats_data['25%']),
                    ("Q3 (75%)", stats_data['75%']),
                    ("IQR", stats_data['75%'] - stats_data['25%'])
                ]
                
                for i, (name, value) in enumerate(metrics):
                    with [col1, col2, col3, col4][i % 4]:
                        if not np.isnan(value):
                            st.metric(name, f"{value:.4f}" if isinstance(value, (int, float)) else str(value))
                
                # An√°lise de distribui√ß√£o COMPLETA
                st.subheader("üìà An√°lise de Distribui√ß√£o")
                
                dist_col1, dist_col2 = st.columns(2)
                
                with dist_col1:
                    # Coeficientes de forma
                    skewness = dados_analise[coluna_analise].skew()
                    kurtosis = dados_analise[coluna_analise].kurtosis()
                    
                    st.write("**üìä Medidas de Forma:**")
                    st.metric("Assimetria", f"{skewness:.3f}")
                    st.metric("Curtose", f"{kurtosis:.3f}")
                    
                    # Teste de normalidade
                    if len(dados_analise[coluna_analise].dropna()) > 3:
                        stat_norm, p_norm = stats.normaltest(dados_analise[coluna_analise].dropna())
                        st.metric("p-valor (Normalidade)", f"{p_norm:.4f}")
                    
                    # Interpreta√ß√£o
                    st.write("**üìù Interpreta√ß√£o:**")
                    if abs(skewness) < 0.5:
                        st.success("‚Ä¢ Distribui√ß√£o aproximadamente sim√©trica")
                    elif abs(skewness) < 1:
                        st.warning("‚Ä¢ Distribui√ß√£o moderadamente assim√©trica")
                    else:
                        st.error("‚Ä¢ Distribui√ß√£o fortemente assim√©trica")
                    
                    if abs(kurtosis) < 0.5:
                        st.success("‚Ä¢ Curtose pr√≥xima da normal")
                    elif abs(kurtosis) < 1:
                        st.warning("‚Ä¢ Curtose moderadamente diferente da normal")
                    else:
                        st.error("‚Ä¢ Curtose muito diferente da normal")
                
                with dist_col2:
                    # Gr√°ficos de distribui√ß√£o
                    fig = px.histogram(dados_analise, x=coluna_analise, 
                                      title=f"Distribui√ß√£o de {coluna_analise}",
                                      nbins=30, marginal="box",
                                      histnorm='probability density')
                    
                    # Adicionar curva normal
                    if len(dados_analise[coluna_analise].dropna()) > 1:
                        x_norm = np.linspace(dados_analise[coluna_analise].min(), 
                                           dados_analise[coluna_analise].max(), 100)
                        y_norm = stats.norm.pdf(x_norm, 
                                              dados_analise[coluna_analise].mean(),
                                              dados_analise[coluna_analise].std())
                        fig.add_trace(go.Scatter(x=x_norm, y=y_norm, 
                                               mode='lines', name='Distribui√ß√£o Normal',
                                               line=dict(color='red', width=2)))
                    
                    st.plotly_chart(fig, use_container_width=True)
                
                # Gr√°fico Q-Q CORRIGIDO
                st.subheader("üìä Gr√°fico Q-Q (An√°lise de Normalidade)")
                fig_qq = criar_qq_plot_correto(dados_analise[coluna_analise])
                st.plotly_chart(fig_qq, use_container_width=True)

    with tab3:
        st.header("üî• An√°lise de Correla√ß√µes")
        
        if len(colunas_numericas) > 1:
            # Selecionar vari√°veis para correla√ß√£o
            st.subheader("üéØ Sele√ß√£o de Vari√°veis")
            variaveis_selecionadas = st.multiselect(
                "Selecione as vari√°veis para an√°lise de correla√ß√£o:",
                options=colunas_numericas,
                default=colunas_numericas[:min(8, len(colunas_numericas))],
                key=generate_unique_key("corr_vars", "tab3")
            )
            
            if len(variaveis_selecionadas) > 1:
                # Op√ß√µes de an√°lise
                col_opt1, col_opt2 = st.columns(2)
                with col_opt1:
                    remover_outliers_corr = st.checkbox("üìâ Remover outliers para an√°lise",
                                                       key=generate_unique_key("remove_corr_outliers", "tab3"))
                with col_opt2:
                    metodo_corr = st.selectbox("M√©todo de correla√ß√£o:",
                                              ["Pearson", "Spearman", "Kendall"],
                                              key=generate_unique_key("corr_method", "tab3"))
                
                dados_corr = dados_processados.copy()
                if remover_outliers_corr:
                    for var in variaveis_selecionadas:
                        outliers_df, outliers_mask = detectar_outliers(dados_corr, var)
                        dados_corr = dados_corr[~outliers_mask]
                    st.info("Outliers removidos de todas as vari√°veis selecionadas")
                
                # Matriz de correla√ß√£o
                if metodo_corr == "Pearson":
                    corr_matrix = dados_corr[variaveis_selecionadas].corr(method='pearson')
                elif metodo_corr == "Spearman":
                    corr_matrix = dados_corr[variaveis_selecionadas].corr(method='spearman')
                else:
                    corr_matrix = dados_corr[variaveis_selecionadas].corr(method='kendall')
                
                fig = px.imshow(corr_matrix, 
                               title=f"Matriz de Correla√ß√£o ({metodo_corr})",
                               color_continuous_scale="RdBu_r",
                               aspect="auto",
                               text_auto=True)
                st.plotly_chart(fig, use_container_width=True)
                
                # An√°lise detalhada de correla√ß√µes
                st.subheader("üîç An√°lise Detalhada das Correla√ß√µes")
                
                correlations = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        corr_value = corr_matrix.iloc[i, j]
                        correlations.append({
                            'Vari√°vel 1': corr_matrix.columns[i],
                            'Vari√°vel 2': corr_matrix.columns[j],
                            'Correla√ß√£o': corr_value,
                            '|Correla√ß√£o|': abs(corr_value)
                        })
                
                df_corr = pd.DataFrame(correlations)
                
                col_ana1, col_ana2 = st.columns(2)
                
                with col_ana1:
                    st.write("**üìà Top 10 Maiores Correla√ß√µes:**")
                    top_correlations = df_corr.nlargest(10, '|Correla√ß√£o|')
                    for _, row in top_correlations.iterrows():
                        corr_value = row['Correla√ß√£o']
                        corr_color = "üü¢" if corr_value > 0 else "üî¥"
                        corr_strength = "Forte" if abs(corr_value) > 0.7 else "Moderada" if abs(corr_value) > 0.3 else "Fraca"
                        st.write(f"{corr_color} **{corr_value:.3f}** - {corr_strength}")
                        st.write(f"   {row['Vari√°vel 1']} ‚Üî {row['Vari√°vel 2']}")
                        st.write("---")
                
                with col_ana2:
                    st.write("**üìâ Top 10 Menores Correla√ß√µes:**")
                    bottom_correlations = df_corr.nsmallest(10, '|Correla√ß√£o|')
                    for _, row in bottom_correlations.iterrows():
                        corr_value = row['Correla√ß√£o']
                        corr_color = "üü¢" if corr_value > 0 else "üî¥"
                        corr_strength = "Fraca"
                        st.write(f"{corr_color} **{corr_value:.3f}** - {corr_strength}")
                        st.write(f"   {row['Vari√°vel 1']} ‚Üî {row['Vari√°vel 2']}")
                        st.write("---")

    with tab4:
        st.header("üîç Gr√°ficos de Dispers√£o com Regress√£o")
        
        if len(colunas_numericas) >= 2:
            col1, col2 = st.columns(2)
            with col1:
                eixo_x = st.selectbox("Eixo X:", colunas_numericas, 
                                     key=generate_unique_key("scatter_x", "tab4"))
            with col2:
                eixo_y = st.selectbox("Eixo Y:", colunas_numericas,
                                     key=generate_unique_key("scatter_y", "tab4"))
            
            if eixo_x and eixo_y:
                # Op√ß√µes avan√ßadas
                col_opt1, col_opt2, col_opt3 = st.columns(3)
                with col_opt1:
                    remover_outliers_grafico = st.checkbox("üìâ Remover outliers",
                                                          key=generate_unique_key("remove_scatter_outliers", f"{eixo_x}_{eixo_y}"))
                with col_opt2:
                    mostrar_regressao = st.checkbox("üìà Mostrar regress√£o", value=True,
                                                   key=generate_unique_key("show_regression", f"{eixo_x}_{eixo_y}"))
                with col_opt3:
                    color_by = st.selectbox("Colorir por:", [""] + colunas_numericas,
                                           key=generate_unique_key("color_by", f"{eixo_x}_{eixo_y}"))
                
                dados_scatter = dados_processados.copy()
                if remover_outliers_grafico:
                    outliers_x, outliers_mask_x = detectar_outliers(dados_scatter, eixo_x)
                    outliers_y, outliers_mask_y = detectar_outliers(dados_scatter, eixo_y)
                    outliers_mask = outliers_mask_x | outliers_mask_y
                    dados_scatter = dados_scatter[~outliers_mask]
                    st.info(f"üìä {outliers_mask.sum()} outliers removidos para visualiza√ß√£o")
                
                # Gr√°fico de dispers√£o
                if color_by and color_by in dados_scatter.columns:
                    fig = px.scatter(dados_scatter, x=eixo_x, y=eixo_y, color=color_by,
                                    title=f"{eixo_y} vs {eixo_x} (Colorido por {color_by})")
                else:
                    fig = px.scatter(dados_scatter, x=eixo_x, y=eixo_y, 
                                    title=f"{eixo_y} vs {eixo_x}")
                
                # Calcular regress√£o linear manualmente
                if mostrar_regressao:
                    slope, intercept, r_squared = calcular_regressao_linear(
                        dados_scatter[eixo_x].values,
                        dados_scatter[eixo_y].values
                    )
                    
                    # Adicionar linha de regress√£o manualmente se poss√≠vel
                    if slope is not None and intercept is not None:
                        x_range = np.linspace(dados_scatter[eixo_x].min(), dados_scatter[eixo_x].max(), 100)
                        y_pred = slope * x_range + intercept
                        
                        fig.add_trace(go.Scatter(
                            x=x_range,
                            y=y_pred,
                            mode='lines',
                            name='Linha de Regress√£o',
                            line=dict(color='red', width=3)
                        ))
                        
                        # Adicionar equa√ß√£o da reta
                        equation = f"y = {slope:.4f}x + {intercept:.4f}"
                        r2_text = f"R¬≤ = {r_squared:.4f}"
                        
                        fig.add_annotation(
                            x=0.05,
                            y=0.95,
                            xref="paper",
                            yref="paper",
                            text=f"<b>{equation}<br>{r2_text}</b>",
                            showarrow=False,
                            font=dict(size=14, color="black"),
                            bgcolor="white",
                            bordercolor="black",
                            borderwidth=2,
                            borderpad=4,
                            opacity=0.8
                        )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Estat√≠sticas de correla√ß√£o COMPLETAS
                st.subheader("üìä Estat√≠sticas de Correla√ß√£o e Regress√£o")
                
                correlacao_pearson = dados_scatter[eixo_x].corr(dados_scatter[eixo_y])
                correlacao_spearman = dados_scatter[eixo_x].corr(dados_scatter[eixo_y], method='spearman')
                
                col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)
                with col_stat1:
                    st.metric("Correla√ß√£o (Pearson)", f"{correlacao_pearson:.4f}")
                with col_stat2:
                    st.metric("Correla√ß√£o (Spearman)", f"{correlacao_spearman:.4f}")
                with col_stat3:
                    if r_squared is not None:
                        st.metric("Coeficiente R¬≤", f"{r_squared:.4f}")
                with col_stat4:
                    if slope is not None:
                        st.metric("Inclina√ß√£o", f"{slope:.4f}")

    with tab5:
        st.header("üéØ Controle Estat√≠stico do Processo")
        
        if colunas_numericas:
            coluna_controle = st.selectbox("Selecione a vari√°vel para controle:", colunas_numericas,
                                          key=generate_unique_key("control_chart_var", "tab5"))
            
            coluna_data_controle = None
            if colunas_data:
                coluna_data_controle = st.selectbox("Selecione a coluna de data (opcional):", 
                                                   [""] + colunas_data,
                                                   key=generate_unique_key("control_chart_date", "tab5"))
            
            if coluna_controle:
                # Gr√°fico de controle
                if coluna_data_controle:
                    fig_controle, lsc, lc, lic = criar_grafico_controle(
                        dados_processados, coluna_controle, coluna_data_controle
                    )
                else:
                    fig_controle, lsc, lc, lic = criar_grafico_controle(
                        dados_processados, coluna_controle
                    )
                
                st.plotly_chart(fig_controle, use_container_width=True)
                
                # Estat√≠sticas de controle
                st.subheader("üìä Estat√≠sticas de Controle")
                
                dados_controle = dados_processados[coluna_controle].dropna()
                media = dados_controle.mean()
                std = dados_controle.std()
                
                col_ctrl1, col_ctrl2, col_ctrl3, col_ctrl4 = st.columns(4)
                with col_ctrl1:
                    st.metric("Linha Central (LC)", f"{lc:.4f}")
                    st.metric("M√©dia", f"{media:.4f}")
                with col_ctrl2:
                    st.metric("LSC", f"{lsc:.4f}")
                    st.metric("+3œÉ", f"{media + 3*std:.4f}")
                with col_ctrl3:
                    st.metric("LIC", f"{lic:.4f}")
                    st.metric("-3œÉ", f"{media - 3*std:.4f}")
                with col_ctrl4:
                    # Pontos fora dos limites
                    pontos_fora = ((dados_controle > lsc) | (dados_controle < lic)).sum()
                    percentual_fora = (pontos_fora / len(dados_controle)) * 100
                    st.metric("Pontos Fora", f"{pontos_fora} ({percentual_fora:.1f}%)")
                
                # An√°lise de capacidade do processo
                st.subheader("üìà An√°lise de Capacidade do Processo")
                
                lse = st.session_state.lse_values.get(coluna_controle, 0)
                lie = st.session_state.lie_values.get(coluna_controle, 0)
                
                if lse != 0 or lie != 0:
                    capacidade = analise_capacidade_processo(dados_processados, coluna_controle, lse, lie)
                    
                    if capacidade:
                        col_cap1, col_cap2, col_cap3 = st.columns(3)
                        with col_cap1:
                            if 'cp' in capacidade:
                                st.metric("Cp", f"{capacidade['cp']:.3f}")
                            if 'cpk' in capacidade:
                                st.metric("Cpk", f"{capacidade['cpk']:.3f}")
                        with col_cap2:
                            st.metric("LSE", f"{lse:.3f}")
                            st.metric("LIE", f"{lie:.3f}")
                        with col_cap3:
                            # Interpreta√ß√£o da capacidade
                            if 'cpk' in capacidade:
                                cpk = capacidade['cpk']
                                if cpk >= 1.33:
                                    st.success("‚úÖ Processo Capaz")
                                elif cpk >= 1.0:
                                    st.warning("‚ö†Ô∏è Processo Marginalmente Capaz")
                                else:
                                    st.error("‚ùå Processo Incapaz")

    with tab6:
        st.header("üìã Resumo Executivo")
        
        # M√©tricas gerais
        st.subheader("üìä Vis√£o Geral do Processo")
        
        col_res1, col_res2, col_res3, col_res4 = st.columns(4)
        with col_res1:
            st.metric("Total de Amostras", len(dados_processados))
            st.metric("Vari√°veis Num√©ricas", len(colunas_numericas))
        with col_res2:
            st.metric("Vari√°veis de Data", len(colunas_data))
            st.metric("Dados Faltantes", dados_processados.isnull().sum().sum())
        with col_res3:
            # Estat√≠sticas gerais das vari√°veis num√©ricas
            if colunas_numericas:
                media_geral = dados_processados[colunas_numericas].mean().mean()
                st.metric("M√©dia Geral", f"{media_geral:.2f}")
        with col_res4:
            if colunas_numericas:
                std_geral = dados_processados[colunas_numericas].std().mean()
                st.metric("Desvio Padr√£o M√©dio", f"{std_geral:.2f}")
        
        # Top vari√°veis mais vari√°veis
        st.subheader("üéØ Vari√°veis com Maior Variabilidade")
        if colunas_numericas:
            variabilidades = dados_processados[colunas_numericas].std().sort_values(ascending=False)
            top_vari√°veis = variabilidades.head(5)
            
            for var, std_val in top_vari√°veis.items():
                st.write(f"‚Ä¢ **{var}**: {std_val:.4f}")
        
        # Alertas e insights
        st.subheader("üö® Alertas e Insights")
        
        # Verificar outliers em todas as vari√°veis
        total_outliers = 0
        for coluna in colunas_numericas:
            outliers_df, _ = detectar_outliers(dados_processados, coluna)
            total_outliers += len(outliers_df)
        
        if total_outliers > 0:
            st.warning(f"‚ö†Ô∏è **{total_outliers} outliers** detectados no processo")
        
        # Verificar dados faltantes
        dados_faltantes = dados_processados.isnull().sum().sum()
        if dados_faltantes > 0:
            st.warning(f"‚ö†Ô∏è **{dados_faltantes} dados faltantes** encontrados")
        
        # Verificar estabilidade do processo
        if colunas_numericas:
            # Calcular coeficiente de varia√ß√£o m√©dio
            coef_variacao_medio = (dados_processados[colunas_numericas].std() / 
                                 dados_processados[colunas_numericas].mean()).mean()
            
            if coef_variacao_medio > 0.5:
                st.warning("‚ö†Ô∏è **Alta variabilidade** detectada no processo")
            elif coef_variacao_medio < 0.1:
                st.success("‚úÖ **Baixa variabilidade** - Processo est√°vel")

    # Download dos dados processados
    st.sidebar.header("üíæ Exportar Dados")
    csv = dados_processados.to_csv(index=False)
    st.sidebar.download_button(
        label="üì• Baixar dados processados (CSV)",
        data=csv,
        file_name="dados_processados.csv",
        mime="text/csv",
        key=generate_unique_key("download_csv", "main")
    )
    
    # Download do relat√≥rio em Excel
    @st.cache_data
    def to_excel(df):
        output = BytesIO()
        writer = pd.ExcelWriter(output, engine='xlsxwriter')
        df.to_excel(writer, index=False, sheet_name='Dados_Processados')
        writer.close()
        processed_data = output.getvalue()
        return processed_data
    
    try:
        from io import BytesIO
        excel_data = to_excel(dados_processados)
        st.sidebar.download_button(
            label="üì• Baixar dados processados (Excel)",
            data=excel_data,
            file_name="dados_processados.xlsx",
            mime="application/vnd.ms-excel",
            key=generate_unique_key("download_excel", "main")
        )
    except:
        pass

if __name__ == "__main__":
    main()
